name: Code Review Assistant

on:
  pull_request:
    types: [opened, reopened, synchronize]

permissions:
  contents: read
  pull-requests: write

jobs:
  review:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Ollama (local LLM runtime)
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          nohup ollama serve > /tmp/ollama.log 2>&1 &
          # wait for API to come up
          timeout 120s bash -c 'until curl -s http://127.0.0.1:11434/api/tags >/dev/null; do sleep 2; done'
          # Pull a small, capable code model (free)
          ollama pull qwen2.5-coder:7b-instruct
        env:
          OLLAMA_HOST: 127.0.0.1

      - name: Run analyzers + LLM review and post PR comment
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          LLM_MODEL: qwen2.5-coder:7b-instruct
        run: |
          python scripts/ci_review.py
